{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XvCUmCEd4Dm"
      },
      "source": [
        "# TensorFlow Datasets\n",
        "\n",
        "TFDS provides a collection of ready-to-use datasets for use with TensorFlow, Jax, and other Machine Learning frameworks.\n",
        "\n",
        "It handles downloading and preparing the data deterministically and constructing a `tf.data.Dataset` (or `np.array`).\n",
        "\n",
        "Note: Do not confuse [TFDS](https://www.tensorflow.org/datasets) (this library) with `tf.data` (TensorFlow API to build efficient data pipelines). TFDS is a high level wrapper around `tf.data`. If you're not familiar with this API, we encourage you to read [the official tf.data guide](https://www.tensorflow.org/guide/data) first.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8y9ZkLXmAZc"
      },
      "source": [
        "Copyright 2018 The TensorFlow Datasets Authors, Licensed under the Apache License, Version 2.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGw9EgE0tC0C"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.tensorflow.org/datasets/overview\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/datasets/blob/master/docs/overview.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/datasets/blob/master/docs/overview.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://storage.googleapis.com/tensorflow_docs/datasets/docs/overview.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7hshda5eaGL"
      },
      "source": [
        "## Installation\n",
        "\n",
        "TFDS는 두 가지 패키지로 존재합니다.\n",
        "\n",
        "- `pip install tensorflow-datasets`: The stable version, released every few months.\n",
        "- `pip install tfds-nightly`: Released every day, contains the last versions of the datasets.\n",
        "\n",
        "This colab uses `tfds-nightly`:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "both",
        "id": "boeZp0sYbO41"
      },
      "outputs": [],
      "source": [
        "!pip install -q tfds-nightly tensorflow matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TTBSvHcSLBzc"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "import tensorflow_datasets as tfds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZZyuO13fPvk"
      },
      "source": [
        "## 사용 가능한 데이터세트 찾기\n",
        "\n",
        "모든 데이터세트 빌더는 `tfds.core.DatasetBuilder`의 서브 클래스입니다. 사용 가능한 빌더의 목록을 얻으려면, `tfds.list_builders()`를 사용하거나 [카탈로그](https://www.tensorflow.org/datasets/catalog/overview)를 살펴보세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FAvbSVzjLCIb"
      },
      "outputs": [],
      "source": [
        "tfds.list_builders()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjI6VgOBf0v0"
      },
      "source": [
        "## 데이터세트 로드하기\n",
        "\n",
        "### tfds.load\n",
        "\n",
        "데이터세트를 로드하는 가장 쉬운 방법은 `tfds.load`입니다.\n",
        "\n",
        "1. 데이터를 다운로드하여 [`tfrecord`](https://www.tensorflow.org/tutorials/load_data/tfrecord) 파일로 저장합니다.\n",
        "2. `tfrecord`를 로드하고 `tf.data.Dataset`를 생성합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dCou80mnLLPV"
      },
      "outputs": [],
      "source": [
        "ds = tfds.load('mnist', split='train', shuffle_files=True)\n",
        "assert isinstance(ds, tf.data.Dataset)\n",
        "print(ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "byOXYCEJS7S6"
      },
      "source": [
        "몇 가지 일반적인 인수:\n",
        "\n",
        "- `split=`: 읽을 분할(예: `'train'`, `['train', 'test']`, `'train[80%:]'`,...). [분할 API 가이드](https://www.tensorflow.org/datasets/splits)를 참조하세요.\n",
        "- `shuffle_files=`: 각 epoch 간에 파일을 셔플할지 여부를 제어합니다(TFDS는 큰 데이터세트를 여러 개의 작은 파일에 저장합니다).\n",
        "- `data_dir=`: 데이터세트가 저장된 위치(기본값은 `~/tensorflow_datasets/`)\n",
        "- `with_info=True`: 데이터세트 메타 데이터를 포함하는 `tfds.core.DatasetInfo`를 반환합니다.\n",
        "- `download=False`: 다운로드를 비활성화합니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qeNmFx_1RXCb"
      },
      "source": [
        "### tfds.builder\n",
        "\n",
        "`tfds.load`는 `tfds.core.DatasetBuilder`를 둘러싼 얇은 래퍼입니다. `tfds.core.DatasetBuilder` API를 사용하여 같은 출력을 얻을 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2zN_jQ2ER40W"
      },
      "outputs": [],
      "source": [
        "builder = tfds.builder('mnist')\n",
        "# 1. Create the tfrecord files (no-op if already exists)\n",
        "builder.download_and_prepare()\n",
        "# 2. Load the `tf.data.Dataset`\n",
        "ds = builder.as_dataset(split='train', shuffle_files=True)\n",
        "print(ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IwrjccfjoQCD"
      },
      "source": [
        "### `tfds build` CLI\n",
        "\n",
        "If you want to generate a specific dataset, you can use the [`tfds` command line](https://www.tensorflow.org/datasets/cli). For example:\n",
        "\n",
        "```sh\n",
        "tfds build mnist\n",
        "```\n",
        "\n",
        "See [the doc](https://www.tensorflow.org/datasets/cli) for available flags."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aW132I-rbJXE"
      },
      "source": [
        "## 데이터세트 반복하기\n",
        "\n",
        "### dict\n",
        "\n",
        "기본적으로 `tf.data.Dataset` 객체에는 `tf.Tensor`의 `dict`가 포함됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JAGjXdk_bIYQ"
      },
      "outputs": [],
      "source": [
        "ds = tfds.load('mnist', split='train')\n",
        "ds = ds.take(1)  # Only take a single example\n",
        "\n",
        "for example in ds:  # example is `{'image': tf.Tensor, 'label': tf.Tensor}`\n",
        "  print(list(example.keys()))\n",
        "  image = example[\"image\"]\n",
        "  label = example[\"label\"]\n",
        "  print(image.shape, label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sIqX2bmhu-8d"
      },
      "source": [
        "To find out the `dict` key names and structure, look at the dataset documentation in [our catalog](https://www.tensorflow.org/datasets/catalog/overview#all_datasets). For example: [mnist documentation](https://www.tensorflow.org/datasets/catalog/mnist)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umAtqBBqdkDG"
      },
      "source": [
        "### As tuple (`as_supervised=True`)\n",
        "\n",
        "`as_supervised=True`를 사용하면 감독된 데이터세트 대신 튜플 `(features, label)`을 얻을 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nJ4O0xy3djfV"
      },
      "outputs": [],
      "source": [
        "ds = tfds.load('mnist', split='train', as_supervised=True)\n",
        "ds = ds.take(1)\n",
        "\n",
        "for image, label in ds:  # example is (image, label)\n",
        "  print(image.shape, label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9palgyHfEwQ"
      },
      "source": [
        "### As numpy (`tfds.as_numpy`)\n",
        "\n",
        "`tfds.as_numpy`를 사용하여 변환합니다.\n",
        "\n",
        "- `tf.Tensor` -&gt; `np.array`\n",
        "- `tf.data.Dataset` -&gt; `Iterator[Tree[np.array]]` (`Tree` can be arbitrary nested `Dict`, `Tuple`)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tzQTCUkAfe9R"
      },
      "outputs": [],
      "source": [
        "ds = tfds.load('mnist', split='train', as_supervised=True)\n",
        "ds = ds.take(1)\n",
        "\n",
        "for image, label in tfds.as_numpy(ds):\n",
        "  print(type(image), type(label), label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XaRN-LdXUkl_"
      },
      "source": [
        "### As batched tf.Tensor (`batch_size=-1`)\n",
        "\n",
        "`batch_size=-1`을 사용하여 전체 데이터세트를 단일 배치로 로드할 수 있습니다.\n",
        "\n",
        "This can be combined with `as_supervised=True` and `tfds.as_numpy` to get the the data as `(np.array, np.array)`:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gg8BNsv-UzFl"
      },
      "outputs": [],
      "source": [
        "image, label = tfds.as_numpy(tfds.load(\n",
        "    'mnist',\n",
        "    split='test',\n",
        "    batch_size=-1,\n",
        "    as_supervised=True,\n",
        "))\n",
        "\n",
        "print(type(image), image.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRJrB3L6wgKI"
      },
      "source": [
        "Be careful that your dataset can fit in memory, and that all examples have the same shape."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "heaKNg7-X4jN"
      },
      "source": [
        "## Benchmark your datasets\n",
        "\n",
        "Benchmarking a dataset is a simple `tfds.benchmark` call on any iterable (e.g. `tf.data.Dataset`, `tfds.as_numpy`,...).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZyQzZ98bX3dM"
      },
      "outputs": [],
      "source": [
        "ds = tfds.load('mnist', split='train')\n",
        "ds = ds.batch(32).prefetch(1)\n",
        "\n",
        "tfds.benchmark(ds, batch_size=32)\n",
        "tfds.benchmark(ds, batch_size=32)  # Second epoch much faster due to auto-caching"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MT0yEX_4kYnV"
      },
      "source": [
        "* Do not forget to normalize the results per batch size with the `batch_size=` kwarg.\n",
        "* In the summary, the first warmup batch is separated from the other ones to capture `tf.data.Dataset` extra setup time (e.g. buffers initialization,...).\n",
        "* Notice how the second iteration is much faster due to [TFDS auto-caching](https://www.tensorflow.org/datasets/performances#auto-caching).\n",
        "* `tfds.benchmark` returns a `tfds.core.BenchmarkResult` which can be inspected for further analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-cuwvVbeb43"
      },
      "source": [
        "### 엔드 투 엔드 파이프라인 빌드하기\n",
        "\n",
        "더 진행하려면, 다음을 살펴볼 수 있습니다.\n",
        "\n",
        "- 전체 훈련 파이프라인(배치 처리, 셔플링 등)을 확인하는 [엔드 투 엔드 Keras 예제](https://www.tensorflow.org/datasets/keras_example)\n",
        "- Our [performance guide](https://www.tensorflow.org/datasets/performances) to improve the speed of your pipelines (tip: use `tfds.benchmark(ds)` to benchmark your datasets).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTRTEQqscxAE"
      },
      "source": [
        "## Visualization\n",
        "\n",
        "### tfds.as_dataframe\n",
        "\n",
        "`tf.data.Dataset` objects can be converted to [`pandas.DataFrame`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html) with `tfds.as_dataframe` to be visualized on [Colab](https://colab.research.google.com).\n",
        "\n",
        "* Add the `tfds.core.DatasetInfo` as second argument of `tfds.as_dataframe` to visualize images, audio, texts, videos,...\n",
        "* Use `ds.take(x)` to only display the first `x` examples. `pandas.DataFrame` will load the full dataset in-memory, and can be very expensive to display."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FKouwN_yVSGQ"
      },
      "outputs": [],
      "source": [
        "ds, info = tfds.load('mnist', split='train', with_info=True)\n",
        "\n",
        "tfds.as_dataframe(ds.take(4), info)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-eDO_EXVGWC"
      },
      "source": [
        "### tfds.show_examples\n",
        "\n",
        "`tfds.show_examples` returns a `matplotlib.figure.Figure` (only image datasets supported now):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DpE2FD56cSQR"
      },
      "outputs": [],
      "source": [
        "ds, info = tfds.load('mnist', split='train', with_info=True)\n",
        "\n",
        "fig = tfds.show_examples(ds, info)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0iVVStvk0oI"
      },
      "source": [
        "## 데이터세트 메타 데이터에 액세스하기\n",
        "\n",
        "모든 빌더에는 데이터세트 메타 데이터를 포함하는 `tfds.core.DatasetInfo` 객체가 포함됩니다.\n",
        "\n",
        "다음을 통해 액세스할 수 있습니다.\n",
        "\n",
        "- `tfds.load` API:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UgLgtcd1ljzt"
      },
      "outputs": [],
      "source": [
        "ds, info = tfds.load('mnist', with_info=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XodyqNXrlxTM"
      },
      "source": [
        "- `tfds.core.DatasetBuilder` API:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nmq97QkilxeL"
      },
      "outputs": [],
      "source": [
        "builder = tfds.builder('mnist')\n",
        "info = builder.info"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMGOk_ZsmPeu"
      },
      "source": [
        "데이터세트 정보에는 데이터세트에 대한 추가 정보(버전, 인용, 홈페이지, 설명 등)가 포함됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O-wLIKD-mZQT"
      },
      "outputs": [],
      "source": [
        "print(info)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zvAfRtwnAFk"
      },
      "source": [
        "### 특성 메타 데이터(레이블 이름, 이미지 형상 등)\n",
        "\n",
        "`tfds.features.FeatureDict`에 액세스합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RcyZXncqoFab"
      },
      "outputs": [],
      "source": [
        "info.features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAm9AV7loyw5"
      },
      "source": [
        "클래스 수, 레이블 이름:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HhfzBH6qowpz"
      },
      "outputs": [],
      "source": [
        "print(info.features[\"label\"].num_classes)\n",
        "print(info.features[\"label\"].names)\n",
        "print(info.features[\"label\"].int2str(7))  # Human readable version (8 -> 'cat')\n",
        "print(info.features[\"label\"].str2int('7'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5eWtk9ro_AK"
      },
      "source": [
        "형상, dtype:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SergV_wQowLY"
      },
      "outputs": [],
      "source": [
        "print(info.features.shape)\n",
        "print(info.features.dtype)\n",
        "print(info.features['image'].shape)\n",
        "print(info.features['image'].dtype)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thMOZ4IKm55N"
      },
      "source": [
        "### 분할 메타 데이터(예: 분할 이름, 예제 수 등)\n",
        "\n",
        "`tfds.core.SplitDict`에 액세스합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FBbfwA8Sp4ax"
      },
      "outputs": [],
      "source": [
        "print(info.splits)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVw1UVYa2HgN"
      },
      "source": [
        "사용 가능한 분할:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fRBieOOquDzX"
      },
      "outputs": [],
      "source": [
        "print(list(info.splits.keys()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHW0VfA0t3dO"
      },
      "source": [
        "Get info on individual split:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-h_OSpRsqKpP"
      },
      "outputs": [],
      "source": [
        "print(info.splits['train'].num_examples)\n",
        "print(info.splits['train'].filenames)\n",
        "print(info.splits['train'].num_shards)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWhSkHFNuLwW"
      },
      "source": [
        "하위 분할 API와도 동작합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HO5irBZ3uIzQ"
      },
      "outputs": [],
      "source": [
        "print(info.splits['train[15%:75%]'].num_examples)\n",
        "print(info.splits['train[15%:75%]'].file_instructions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZp2XJwQQrI0"
      },
      "source": [
        "## Troubleshooting\n",
        "\n",
        "### Manual download (if download fails)\n",
        "\n",
        "If download fails for some reason (e.g. offline,...). You can always manually download the data yourself and place it in the `manual_dir` (defaults to `~/tensorflow_datasets/download/manual/`.\n",
        "\n",
        "To find out which urls to download, look into:\n",
        "\n",
        " * For new datasets (implemented as folder): [`tensorflow_datasets/`](https://github.com/tensorflow/datasets/tree/master/tensorflow_datasets/)`<type>/<dataset_name>/checksums.tsv`. For example: [`tensorflow_datasets/text/bool_q/checksums.tsv`](https://github.com/tensorflow/datasets/blob/master/tensorflow_datasets/text/bool_q/checksums.tsv).\n",
        "\n",
        "   You can find the dataset source location in [our catalog](https://www.tensorflow.org/datasets/catalog/overview).\n",
        " * For old datasets: [`tensorflow_datasets/url_checksums/<dataset_name>.txt`](https://github.com/tensorflow/datasets/tree/master/tensorflow_datasets/url_checksums)\n",
        "\n",
        "### Fixing `NonMatchingChecksumError`\n",
        "\n",
        "TFDS ensure determinism by validating the checksums of downloaded urls.\n",
        "If `NonMatchingChecksumError` is raised, might indicate:\n",
        "\n",
        "  * The website may be down (e.g. `503 status code`). Please check the url.\n",
        "  * For Google Drive URLs, try again later as Drive sometimes rejects downloads when too many people access the same URL. See [bug](https://github.com/tensorflow/datasets/issues/1482)\n",
        "  * The original datasets files may have been updated. In this case the TFDS dataset builder should be updated. Please open a new Github issue or PR:\n",
        "     * Register the new checksums with `tfds build --register_checksums`\n",
        "     * Eventually update the dataset generation code.\n",
        "     * Update the dataset `VERSION`\n",
        "     * Update the dataset `RELEASE_NOTES`: What caused the checksums to change ? Did some examples changed ?\n",
        "     * Make sure the dataset can still be built.\n",
        "     * Send us a PR\n",
        "\n",
        "Note: You can also inspect the downloaded file in `~/tensorflow_datasets/download/`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmeeOokMODg2"
      },
      "source": [
        "## 인용\n",
        "\n",
        "If you're using `tensorflow-datasets` for a paper, please include the following citation, in addition to any citation specific to the used datasets (which can be found in the [dataset catalog](https://www.tensorflow.org/datasets/catalog/overview)).\n",
        "\n",
        "```\n",
        "@misc{TFDS,\n",
        "  title = { {TensorFlow Datasets}, A collection of ready-to-use datasets},\n",
        "  howpublished = {\\url{https://www.tensorflow.org/datasets}},\n",
        "}\n",
        "```"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "overview.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
